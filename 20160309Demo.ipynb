{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.55\n",
      "行政院環境保護署\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "with open('gov/51787884.txt','r') as f:\n",
    "    soup = bs(f.read())\n",
    "    for tr in soup.select('tr'):\n",
    "        th = tr.select('th')\n",
    "        if len(th) > 0 :\n",
    "            if th[0].text.encode('utf-8').strip() == '機關代碼':\n",
    "                td = tr.select('td')[0].text.strip()\n",
    "                print td\n",
    "            if th[0].text.encode('utf-8').strip() == '機關名稱':\n",
    "                td = tr.select('td')[0].text.strip()\n",
    "                print td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "dic = {'機關代碼': '', '機關名稱': '', '單位名稱': '' , '機關地址': '', '聯絡電話': ''}\n",
    "with open('gov/51787884.txt','r') as f:\n",
    "    soup = bs(f.read())\n",
    "    for tr in soup.select('tr'):\n",
    "        th = tr.select('th')\n",
    "        if len(th) > 0 :\n",
    "            th_value = th[0].text.encode('utf-8').strip()\n",
    "            if th_value in dic:\n",
    "                td = tr.select('td')[0].text.strip()\n",
    "                dic[th_value] = td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "單位名稱 廢棄物管理處\n",
      "機關名稱 行政院環境保護署\n",
      "機關代碼 3.55\n",
      "聯絡電話 (02)23117722 分機 2624  2481\n",
      "機關地址 100臺北市中正區中華路一段83號\n"
     ]
    }
   ],
   "source": [
    "for key in dic:\n",
    "    print key, dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {'標的分類': ''}\n",
    "with open('gov/51787884.txt','r') as f:\n",
    "    soup = bs(f.read())\n",
    "    for tr in soup.select('tr'):\n",
    "        th = tr.select('th')\n",
    "        if len(th) > 0 :\n",
    "            th_value = th[0].text.encode('utf-8').strip()\n",
    "            if th_value in dic:\n",
    "                td = tr.select('td')[0].text.strip()\n",
    "                dic[th_value] = td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標的分類 u'<\\u52de\\u52d9\\u985e>    \\r\\n                            94\\r\\n                            \\u6c61\\u6c34\\u53ca\\u5783\\u573e\\u8655\\u7406\\u3001\\u516c\\u5171\\u885b\\u751f\\u53ca\\u5176\\u4ed6\\u74b0\\u4fdd\\u670d\\u52d9'\n"
     ]
    }
   ],
   "source": [
    "for ele in dic:\n",
    "    print ele, repr(dic[ele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t \n",
      "\n",
      "123\n",
      "324\t\n",
      "'\\t\\t \\n\\n123\\n324\\t'\n"
     ]
    }
   ],
   "source": [
    "a = '\\t\\t \\n\\n123\\n324\\t'\n",
    "print a\n",
    "print repr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標的分類 <勞務類> 94 污水及垃圾處理、公共衛生及其他環保服務\n"
     ]
    }
   ],
   "source": [
    "for ele in dic:\n",
    "    print ele, ' '.join(dic[ele].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dddddd                  aaaaaaaaa                   bbbbbb   \n",
      "['dddddd', 'aaaaaaaaa', 'bbbbbb']\n",
      "dddddd|aaaaaaaaa|bbbbbb\n",
      "ddddddaaaaaaaaabbbbbb\n"
     ]
    }
   ],
   "source": [
    "a = '         dddddd                  aaaaaaaaa                   bbbbbb   '\n",
    "print a\n",
    "print a.split()\n",
    "print '|'.join(a.split())\n",
    "print ''.join(a.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-09\n",
      "2016-03-09 19:08\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "from datetime import date,datetime \n",
    "currenttime = datetime.now() \n",
    "print currenttime.strftime(\"%Y-%m-%d\") \n",
    "print currenttime.strftime(\"%Y-%m-%d %H:%M\") \n",
    "print type(currenttime.strftime(\"%Y-%m-%d %H:%M\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-05-03 14:00:00\n",
      "676 days, 5:08:38.958000\n"
     ]
    }
   ],
   "source": [
    "a = '2014-05-03 14:00' \n",
    "print datetime.strptime(a, \"%Y-%m-%d %H:%M\")\n",
    "\n",
    "print currenttime - datetime.strptime(a, \"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-09 19:08:38.958000\n",
      "2016-03-08 19:08:38.958000\n",
      "2016/03/08\n",
      "2016/03/07\n",
      "2016/03/06\n",
      "2016/03/05\n",
      "2016/03/04\n",
      "2016/03/03\n",
      "2016/03/02\n",
      "2016/03/01\n",
      "2016/02/29\n",
      "2016/02/28\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "print currenttime \n",
    "print currenttime - timedelta(days = 1)\n",
    "\n",
    "for i in xrange(1,11):\n",
    "    print (currenttime - timedelta(days = i)).strftime('%Y/%m/%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['102', '12', '10 10:30']\n",
      "['102', '12/10 10:30']\n",
      "102\n",
      "2013\n",
      "2013/12/10 10:30\n"
     ]
    }
   ],
   "source": [
    "response_date = '102/12/10 10:30' \n",
    "print response_date.split('/') \n",
    "print response_date.split('/', 1) \n",
    "print response_date.split('/', 1)[0] \n",
    "print int(response_date.split('/', 1)[0] ) + 1911\n",
    "\n",
    "getyear = response_date.split('/', 1)\n",
    "print str(int(getyear[0] ) + 1911 ) + '/' + getyear[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352,111\n",
      "['352', '111']\n",
      "352111\n",
      "352111\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "m = re.match( r\"\\$?(-?[0-9,]+)元\", '352,111元') \n",
    "print m.group(1)\n",
    "print m.group(1).split(',')\n",
    "print ''.join(m.group(1).split(','))\n",
    "print int(''.join(m.group(1).split(',')))\n",
    "#print ''.join(m.group(1).split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n",
      "<_sre.SRE_Match object at 0x0000000003F301D0>\n"
     ]
    }
   ],
   "source": [
    "a = 'apple'\n",
    "print a == 'apple'\n",
    "import re\n",
    "#re.match()\n",
    "#re.search()\n",
    "a = 'apple'\n",
    "#  match word\n",
    "print re.search('c', 'apple')\n",
    "print re.search('a', 'apple')\n",
    "print re.search('[abcdef]', 'apple')\n",
    "print re.search('[abcdefghijklmnopqrstuvwxyz]', 'apple')\n",
    "print re.search('[a-z]', 'apple')\n",
    "# match numeric\n",
    "print re.search('[0123456789]', 'apple1')\n",
    "print re.search('[0-9]', 'apple1')\n",
    "print re.search('\\d', 'apple1') # \\d == [0-9]\n",
    "print re.search('[0-9a-zA-Z]', 'apple1')\n",
    "print re.search('\\w', 'apple1') # \\w == [0-9a-zA-Z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qoo@gmail.com', 'oop@gmail.com']\n",
      "['qpp@gmx.com']\n",
      "['qoo@gmail.com', 'qpp@gmx.com', 'oop@gmail.com']\n",
      "['qoo@gmail.com', 'qpp@gmx.com', 'oop@gmail.com']\n",
      "['qoo@gmail.com', 'qpp@gmx.com', 'oop@gmail.com']\n",
      "['qoo@gmail.com', 'qpp@gmx.com', 'oop@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "#email\n",
    "emails = ['qoo@gmail.com', 'qpp@gmx.com', 'oop@gmail.com', '123@qq.com']\n",
    "print [email for email in emails if re.search('gmail.com' , email)] # match gmail.com only\n",
    "print [email for email in emails if re.search('g\\w{2,3}.com' , email)] # match gxx.com and gxxx.com\n",
    "print [email for email in emails if re.search('g\\w{0,}.com' , email)] # match gxxxxxxxxxx.com or g.com\n",
    "print [email for email in emails if re.search('g\\w*.com' , email)] # {0,} == *\n",
    "print [email for email in emails if re.search('g\\w+.com' , email)] # {1,} == *\n",
    "print [email for email in emails if re.search('g.+\\.com' , email)] # . == \\w\\d!@#@%#$$%&%*&^*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0912345678', '09123456781823791738927398173812783213']\n",
      "['0912345678', '0912-345678', '09123456781823791738927398173812783213']\n",
      "['0912345678', '0912-345678', '0912-345-678', '09123456781823791738927398173812783213']\n",
      "['0912345678', '0912-345678', '0912-345-678']\n"
     ]
    }
   ],
   "source": [
    "phones = ['0912345678', '0912-345678', '0912-345-678', '09123456781823791738927398173812783213']\n",
    "print [phone for phone in phones if re.search('\\d{10}' , phone)]  \n",
    "print [phone for phone in phones if re.search('\\d{4}-?\\d{6}' , phone)]  # {0,1} == ?\n",
    "print [phone for phone in phones if re.search('\\d{4}-?\\d{3}-?\\d{3}' , phone)]  \n",
    "print [phone for phone in phones if re.search('^\\d{4}-?\\d{3}-?\\d{3}$' , phone)]  # ^ initial, $ end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12980\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.get('http://ecapi.pchome.com.tw/ecshop/prodapi/v2/prod/DGBJAG-A9006UP86-000&store=DGBJAG&fields=Seq,Id,Name,Nick,Store,PreOrdDate,SpeOrdDate,Price,Discount,Pic,Weight,ISBN,Qty,Bonus,isBig,isSpec,isCombine,isDiy,isRecyclable,isCarrier,isMedical,isBigCart,isSnapUp,isDescAndIntroSync,isFoodContents,isHuge,isEnergySubsidy&_callback=jsonp_prod?_callback=jsonp_prod')\n",
    "#print res.text\n",
    "import re\n",
    "m = re.search('jsonp_prod\\((.+)\\);}catch\\(e\\)', res.text)\n",
    "import json\n",
    "#print m.group(1) \n",
    "jd = json.loads(m.group(1))\n",
    "print jd['DGBJAG-A9006UP86-000']['Price']['P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "優仕達資訊股份有限公司\n",
      "空姐報報Emily Post\n",
      "LaLa徐佳瑩\n",
      "數位行銷學院 neo Marketing School\n",
      "KumaWash\n",
      "非常木蘭\n",
      "財務數據創新趨勢平台FinDit\n",
      "廖若妤(廖小若)\n",
      "產品開發週刊\n",
      "爆料公社\n",
      "一起看正妹\n",
      "福邸 Foodie\n",
      "GraphicStock\n",
      "白馬八方尾根スキー場\n",
      "Taiwan Startup Stadium 台灣新創競技場\n",
      "Flowing Ocean 孚海國際\n",
      "vonvon.me\n",
      "BBC 中文網（繁體）\n",
      "聞氫哥\n",
      "東吳巨資學院\n",
      "Wikimedia Taiwan\n",
      "Periscope Data\n",
      "BigData Taiwan\n",
      "昕創千萬APP大賽\n",
      "昕電視\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "ACCESSTOKEN  = '<ACCESSTOKEN>'\n",
    "fburl ='https://graph.facebook.com/v2.5/me/likes?access_token={}'\n",
    "res = requests.get(fburl.format(ACCESSTOKEN))\n",
    "\n",
    "jd = json.loads(res.text)\n",
    "for likes in jd['data']:\n",
    "    print likes['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果是影片😂😂😂\n",
      "一直以為是拍照😂\n",
      "☀️☀️☀️\n",
      "Choc girl\n",
      "3月恰女生coming soon\n",
      "今天的動力來源是～希望晚上吃牛排！！！☺️☺️☺️\n",
      "Sprinkles 好吃！！！\n",
      "Newport Beach 很舒服！！\n",
      "Puff Kuo 冬夏混搭 很時尚😂\n",
      "早安啊！\n",
      "...Seriously???\n",
      "看到報導我真的不知道該說什麼，我不是一個人住 車子也不是我一個人的 家裡還有哥哥妹妹們⋯他們也都有自己的生活 如果要因為我 連生活都不能自由了，我想應該沒人想跟我住了⋯\n",
      "對我來說他們都是很乖的弟弟，我也很高興他們跟哥哥很好 \n",
      "至於我平常買的東西都滿中性的\n",
      "可能帶了幾次後會給我哥 那我哥想送給誰 那就是他的自由了 \n",
      "總而言之 我不希望家人和朋友因為我不能有自己的生活或是因為我被誤會被罵 \n",
      "我感到很抱歉  連我哥都能被寫成我緋聞的對象了 現在的報導只要是在我生活圈的異性都會被寫成緋聞吧？？？아  짜증나 好吧！我只好公布我的情人了⋯\n",
      "hi ...nice to meet you ✋🏻\n",
      "Happy Valentine's Day 💗\n",
      "Hi～ it's me～（莎莉：這是圖奇的台詞…\n",
      "看到暖暖的太陽\n",
      "大家新年快樂，新的一年祝福大家都健康平安，也希望大家都能持續關心和幫助台南，也辛苦所有搜救人員和給予協助的大家～希望還能有更多的生還者🙏🏻\n",
      "請大家有錢出錢有力出力，現在台南需要大家的幫助渡過難關～🙏🏻🙏🏻🙏🏻\n",
      "以下是捐款資訊\n",
      "大家可於今日下午4點直接至統一超商全台7-ELEVEN ibon便利生活站點選「台南震災（台南市政府）」捐款按鈕，即可現場繳費捐款，捐款帳號：社會救助金專戶009045065055臺灣銀行台南分行，指定0206震災，民眾若有捐款或物資捐贈詢事宜，可撥打（06）2995805或（06）2991111轉8061，也可傳真（06）2995759。\n",
      "http://www.ettoday.net/news/20160206/645163.htm\n",
      "\n",
      "捐血中心也嚴重血荒\n",
      "請大家多多幫忙～\n",
      "雲嘉南地區10個固定捐血地點，請參考新聞公佈的捐血地點\n",
      "http://m.life.tw/?app=view&no=389239\n",
      "這幾天還是好冷 總是離不開被窩⋯整個人懶懶的 希望過年期間出大太陽 想出去曬一曬 把寒氣和懶散都曬掉！！！\n",
      "#Bella儂儂 2月號 \n",
      "非常喜歡這次的造型風格\n",
      "謝謝Bella 每次的拍攝都很愉快\n",
      "也開始期待下一次的相遇了☺️\n",
      "不知道大家喜歡嗎？😄\n",
      "突然想起在國外出太陽時坐草地看書的畫面 覺得好舒服～😁晚安！\n",
      "編：二月Bella儂儂 封面，敬請期待～\n",
      "\n",
      "http://youtu.be/TgfAr28H9DM\n",
      "路跑初體驗～\n",
      "LOUIS VUITTON FOR unicef\n",
      "\n",
      "#silverlockit 手鍊 \n",
      "LV每售出一件 將有200美金捐至\n",
      "UNICEF聯合國兒童基金會 協助全球\n",
      "需要幫助的孩童  也可以至下方網站直接進行捐款 希望大家可以一起支持\n",
      "給予這些孩子一個美好未來\n",
      "用愛與關懷改變世界\n",
      "@tiffanywenlo \n",
      "#makeapromise    #lvforunicef\n",
      " MAKEAPROMISE\n",
      "了解詳情可以到以下網路\n",
      "www.louisvuitton.com/lvforunicef\n",
      "一度咕 。\n",
      "編：2016年的第一本雜誌，大家都擁有了嗎～1/1已經發行了喔\n",
      "祝大家 新年快樂\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "ACCESSTOKEN ='CAACEdEose0cBAI9iH8FDvm1LIm5nErDrdQZC2GQeeN5hjtWnQHxVWfgv6nG5bZBAXi2ngDS7K01yMhJDqCZBFLNTmJZAnHieTlF37QmUD7FUq2ld1HbaljuXjvIMQ2WZBDZAybRvezqaJAYbfITaZBufdOz2ulxXHL66ZBNp0inyPX6Jda4zVcnHGZBBZB7wQ7gdD2JaYXW2lhqQAOFLa4e5uU'\n",
    "fburl ='https://graph.facebook.com/v2.5/DreamGirlsPuff/posts?access_token={}'\n",
    "res = requests.get(fburl.format(ACCESSTOKEN))\n",
    "\n",
    "jd = json.loads(res.text)\n",
    "for message in jd['data']:\n",
    "    if 'message' in message:\n",
    "        print message['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import jieba\n",
    "from collections import Counter\n",
    "ACCESSTOKEN ='<ACCESSTOKEN>'\n",
    "fburl ='https://graph.facebook.com/v2.5/tsaiingwen/posts?access_token={}'\n",
    "res = requests.get(fburl.format(ACCESSTOKEN))\n",
    "\n",
    "dic = Counter()\n",
    "jd = json.loads(res.text)\n",
    "for message in jd['data']:\n",
    "    if 'message' in message:\n",
    "        for ele in jieba.cut(message['message']):\n",
    "            dic[ele] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我們 68\n",
      "台灣 43\n",
      "產業 25\n",
      "一個 22\n",
      "轉型 21\n",
      "發展 18\n",
      "大家 17\n",
      "一起 16\n",
      "可以 16\n",
      "政府 15\n",
      "社會 15\n",
      "國家 14\n",
      "推動 13\n",
      "未來 13\n",
      "就是 12\n",
      "環境 12\n",
      "農業 11\n",
      "成為 10\n",
      "新政府 10\n",
      "二二八 10\n",
      "透過 10\n",
      "重要 10\n",
      "正義 9\n",
      "努力 9\n",
      "建立 9\n",
      "能源 8\n",
      "和解 8\n",
      "這個 8\n",
      "以及 8\n",
      "團結 8\n",
      "國際 8\n",
      "因為 8\n",
      "goo 7\n",
      "真相 7\n",
      "企業 7\n",
      "土地 7\n",
      "歷史 7\n",
      "政治 7\n",
      "能夠 7\n",
      "合作 7\n",
      "新聞稿 7\n",
      "全文 7\n",
      "gl 7\n",
      "永續 7\n",
      "真正 7\n",
      "http 7\n",
      "面對 6\n",
      "創新 6\n",
      "氫能 6\n",
      "人才 6\n",
      "綠能 6\n"
     ]
    }
   ],
   "source": [
    "for ele in dic.most_common(100):\n",
    "    if len(ele[0]) >= 2:\n",
    "        print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
